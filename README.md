# multimedia
Итоги лабораторных работ:
| **Алгоритм**        | **Задача**     | **Датасет**                | **Бейзлайн** | **Улучшенный** | **Самостоятельная** |  
|----------------------|----------------|----------------------------|--------------|----------------|----------------------|  
| **KNN**             | Классификация | Iris                      | 0.96         | 0.97           | Не делалось          |  
|                     | Регрессия     | California Housing        | 0.54 (R2)    | 0.58 (R2)      | Не делалось          |  
| **Линейные модели**  | Классификация | Iris                      | 0.96         | 0.96           | Не делалось          |  
|                     | Регрессия     | California Housing        | 0.54 (R2)    | 0.55 (R2)      | Не делалось          |  
| **Решающее дерево**  | Классификация | Penguins                  | 0.93         | 0.94           | 0.91                 |  
|                     | Регрессия     | Bike Sharing              | 0.30 (MSE)   | 0.28 (MSE)     | 0.35 (MSE)           |  
| **Случайный лес**    | Классификация | Bank Marketing            | 0.90         | 0.91           | 0.88                 |  
|                     | Регрессия     | Bike Sharing              | 0.24 (MSE)   | 0.22 (MSE)     | 0.26 (MSE)           |  
| **Градиентный**      | Классификация | Heart Disease             | 0.86         | 0.88           | 0.83                 |  
| **бустинг**          | Регрессия     | Airfoil Self-Noise        | 0.22 (MSE)   | 0.20 (MSE)     | 0.23 (MSE)           |  


За время выполнения лабораторных работ я попробовала разные алгоритмы машинного обучения для задач классификации и регрессии. Было интересно наблюдать, как они справляются с разными данными, и что можно улучшить, чтобы получить лучший результат.

1. KNN оказался простым и эффективным для классификации (точность до 97% на Iris), но для регрессии результаты были средними (около 0.54-0.58 R² на California Housing).

2. Линейные модели работали стабильно, но в сложных задачах не показывали значительных улучшений даже после доработки.

3. Решающее дерево справилось отлично с классификацией (до 94% на Penguins) и было полезно для изучения структуры данных. Однако для регрессии (Bike Sharing) результаты были посредственными.

4. Случайный лес показал себя как мощный инструмент, особенно для классификации (точность 91% на Bank Marketing). В регрессии он заметно улучшил результаты по сравнению с обычным деревом.

5. Градиентный бустинг оказался самым точным и универсальным. Он дал отличные результаты как для классификации (88% на Heart Disease), так и для регрессии (минимальная ошибка на Airfoil Self-Noise).

Самостоятельная реализация алгоритмов помогла понять, как они работают внутри. Главный вывод: выбор метода зависит от данных, и сложные алгоритмы, такие как случайный лес и бустинг, дают лучшие результаты на сложных задачах.
