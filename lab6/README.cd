Этот проект решает задачу бинарной классификации изображений на два класса: кошки и собаки, используя предварительно обученные модели глубокого обучения из библиотеки torchvision и другие инструменты на базе PyTorch. В рамках лабораторной работы были рассмотрены следующие этапы:

Загрузка и предобработка данных с использованием Kaggle API.
Обучение моделей: модели сверточных нейронных сетей (CNN) и Vision Transformer (ViT).
Оценка производительности с использованием метрик качества (Accuracy, Precision, Recall, F1-Score, ROC-AUC).
Оптимизация: гипотезы по улучшению модели, включая использование аугментаций данных.
Анализ результатов с помощью графиков.

Выбор моделей

В качестве базовых моделей использованы:

ResNet18: Одна из популярных сверточных нейронных сетей (CNN), хорошо подходящая для классификации изображений.
Vision Transformer (ViT): Используется для задачи классификации, основанной на трансформерах, что является новаторским подходом в области обработки изображений.

Метрики
Для оценки качества моделей используются следующие метрики:

Accuracy: Общая точность классификации.
Precision и Recall: Показатели для оценки ложных положительных и отрицательных классификаций.
F1-Score: Среднее гармоническое между точностью и полнотой.
ROC-AUC: Оценка способности модели различать классы на различных порогах.

Для улучшения производительности модели была предложена гипотеза:

Аугментация данных: добавление случайных поворотов, изменений яркости, контраста и других параметров изображения.
Гиперпараметры: подбор параметров обучения, таких как скорость обучения, количество эпох и размер батча.
Использование других моделей: например, MobileNetV2, чтобы ускорить обучение и уменьшить количество параметров.

Выводы

В рамках данной лабораторной работы была решена задача классификации изображений кошек и собак с использованием глубоких нейронных сетей. 

Основные результаты:
Использование предварительно обученных моделей (таких как ResNet18 и Vision Transformer (ViT)) позволило добиться хороших результатов при классификации изображений, несмотря на ограниченное количество эпох и уменьшенные размеры батчей в связи с долгими расчетами.
Метрики качества, такие как accuracy, precision, recall, F1-score и ROC-AUC, показали сбалансированную картину о производительности моделей. Метрики точности и полноты обеспечили важную информацию о типах ошибок, в частности, о ложных положительных и ложных отрицательных классификациях.
Аугментации данных и использование оптимизаторов, таких как Adam, обеспечили дополнительное улучшение результатов и ускорение процесса обучения.
Графики потерь показали, что обе модели имеют тенденцию к улучшению по мере увеличения числа эпох, что подтверждает правильность выбранного подхода и методов обучения.
Сравнение результатов базовых и улучшенных моделей выявило, что оптимизация гиперпараметров и добавление аугментаций данных могут заметно повысить качество классификации, особенно при ограниченных ресурсах.
